from abc import ABC, abstractmethod
from typing import Any, Dict, List, Optional, Tuple, Union
from datasets import load_dataset
from tqdm import tqdm
import os
import json
import random
from copypastelrm.utils.dataset import NLPTool
# å‡è®¾ BM25Retriever åœ¨è¿™ä¸ªè·¯å¾„ï¼Œä¿æŒå¼•ç”¨ä¸å˜
from copypastelrm.utils.bm25 import BM25Retriever 

class BaseDatasetLoader(ABC):
    """
    æ•°æ®é›†åŠ è½½å™¨çš„åŸºç±»ï¼Œæä¾›ç»Ÿä¸€çš„æ•°æ®é›†åŠ è½½ã€é¢„å¤„ç†ã€BM25ç´¢å¼•æ„å»ºåŠç¼“å­˜ç®¡ç†æ¥å£ã€‚
    """

    def __init__(
        self,
        dataset_path: str,
        split: str,
        cache_dir: str = "data/cache/",  # ç¼“å­˜è·¯å¾„
        dataset_name: Optional[str] = None,
        offline: bool = True,
        reload: bool = False,
        format: bool = True,
        max_samples: int = -1,
        filter_empty_answer: bool = True,
        distractor_docs: int = 8,
        unanswerable: bool = False, 
    ):
        """
        åˆå§‹åŒ–æ•°æ®é›†åŠ è½½å™¨
        """
        self.nlp = NLPTool()
        self.dataset_path = dataset_path
        self.dataset_name = dataset_name
        self.split = split
        self.offline = offline
        self.reload = reload
        self.format = format
        self.filter_empty_answer = filter_empty_answer
        self.unanswerable = unanswerable
        self.distractor_docs = distractor_docs
        
        # æ„å»ºç¼“å­˜æ–‡ä»¶å
        base_name = self.dataset_path.replace('.json', '').replace('/', '-')
        subset_name = f"-{self.dataset_name}" if self.dataset_name else ""
        file_name = f"{base_name}{subset_name}-{self.split}-{self.distractor_docs}-{self.unanswerable}"
        self.cache_path = os.path.join(cache_dir, f"{file_name}.jsonl")

        if self.cache_path and not self.cache_path.endswith(".jsonl"):
            raise ValueError("cache_path must end with .jsonl")

        # -----------------------------------------------------------
        # Step 1: åŠ è½½æ•°æ® (Load Data)
        # è¿”å›æ•°æ®åˆ—è¡¨å’Œæ¥æºæ ‡è®° (æ˜¯å¦æ¥è‡ªç¼“å­˜)
        # -----------------------------------------------------------
        self.dataset_list, self.is_from_cache = self.get_dataset()
        
        if not self.dataset_list:
            print("âš ï¸ Warning: Loaded dataset is empty.")

        # -----------------------------------------------------------
        # Step 2: æ„å»ºæ£€ç´¢å™¨ (Build Retriever)
        # æ— è®ºæ•°æ®æ¥è‡ªç¼“å­˜è¿˜æ˜¯åŸå§‹æºï¼Œä¸ºäº†æ”¯æŒå¤–éƒ¨è°ƒç”¨ bm25ï¼Œæˆ‘ä»¬éƒ½éœ€è¦æ„å»ºç´¢å¼•ã€‚
        # construct_corpus ä¼šæ ¹æ® is_from_cache è‡ªåŠ¨å†³å®šå¦‚ä½•è§£ææ•°æ®ã€‚
        # -----------------------------------------------------------
        print('æ­£åœ¨æ„å»º BM25 è¯­æ–™åº“...')
        self.corpus = self.construct_corpus(self.dataset_list, is_formatted=self.is_from_cache)
        
        if not self.corpus:
            print("âš ï¸ Warning: Corpus is empty. BM25 index will fail.")
        else:
            print(f'è¯­æ–™åº“æ„å»ºå®Œæˆï¼Œå…± {len(self.corpus)} æ¡æ–‡æ¡£ï¼Œå¼€å§‹æ„å»ºç´¢å¼•...')
            self.bm25 = BM25Retriever(self.corpus)

        # -----------------------------------------------------------
        # Step 3: æœ€ç»ˆåŒ–æ•°æ®é›† (Finalize Dataset)
        # å¦‚æœæ¥è‡ªç¼“å­˜ï¼šç›´æ¥æ˜ å°„ä¸ºå­—å…¸ã€‚
        # å¦‚æœæ˜¯åŸå§‹æ•°æ®ï¼šæ‰§è¡Œ format_dataset æµç¨‹ï¼ˆå« BM25 æ£€ç´¢å¹²æ‰°é¡¹ï¼‰å¹¶ç¼“å­˜ã€‚
        # -----------------------------------------------------------
        if self.is_from_cache:
            print('âœ… æ£€æµ‹åˆ°æ•°æ®æ¥è‡ªç¼“å­˜ï¼Œè·³è¿‡æ ¼å¼åŒ–æ­¥éª¤ï¼Œç›´æ¥åŠ è½½ã€‚')
            self.dataset = {sample["id"]: sample for sample in self.dataset_list}
        else:
            print('ğŸ”„ æ•°æ®ä¸ºåŸå§‹æ ¼å¼ï¼Œå¼€å§‹æ‰§è¡Œæ ¼å¼åŒ–ä¸æ£€ç´¢...')
            # åªæœ‰åŸå§‹æ•°æ®æ‰è°ƒç”¨ format_datasetï¼Œé¿å… KeyError
            self.dataset = self.format_dataset(self.dataset_list)

        # -----------------------------------------------------------
        # Step 4: é‡‡æ · (Optional Sampling)
        # -----------------------------------------------------------
        if 0 < max_samples < len(self.dataset_list):
            print(f"Sampling {max_samples} samples from {len(self.dataset_list)} total.")
            self.dataset_list = random.sample(self.dataset_list, max_samples)
            # é‡å»º dataset å­—å…¸æ˜ å°„
            self.dataset = {sample["id"]: sample for sample in self.dataset_list}

        # æœ€ç»ˆä¸€è‡´æ€§æ£€æŸ¥
        assert len(self.dataset_list) == len(self.dataset), "æ•°æ®é›†åˆ—è¡¨å’Œå­—å…¸é•¿åº¦ä¸ä¸€è‡´"
        print('ğŸ‰ æ•°æ®é›†å‡†å¤‡å°±ç»ª')

    def download_dataset(self) -> List[Dict[str, Any]]:
        """é»˜è®¤ä»huggingfaceä¸‹è½½æ•°æ®"""
        print(f"æ­£åœ¨åŠ è½½ {self.dataset_path} æ•°æ®é›†...")
        if self.dataset_name:
            print(f"æ•°æ®é›†å­é›†: {self.dataset_name}")
        print(f"æ•°æ®åˆ†å‰²: {self.split}")

        if self.dataset_name:
            dataset = load_dataset(
                path=self.dataset_path, name=self.dataset_name, split=self.split
            )
        else:
            dataset = load_dataset(path=self.dataset_path, split=self.split)
        
        print(f"æ•°æ®é›†åŠ è½½å®Œæˆï¼Œå…± {len(dataset)} ä¸ªæ ·æœ¬")
        return list(dataset)

    def get_dataset(self) -> Tuple[List[Dict[str, Any]], bool]:
        """
        åŠ è½½æ•°æ®é›†ã€‚
        
        Returns:
            Tuple[List, bool]: (æ•°æ®åˆ—è¡¨, æ˜¯å¦æ¥è‡ªç¼“å­˜)
        """
        # 1. å°è¯•è¯»å–ç¼“å­˜
        if (
            not self.reload
            and self.offline
            and self.cache_path
            and os.path.exists(self.cache_path)
        ):
            try:
                with open(self.cache_path, "r", encoding='utf-8') as f:
                    print(f"ğŸ¯ Loading dataset from cache: {self.cache_path}")
                    formatted_dataset_list = json.load(f)
                    
                    if self.filter_empty_answer:
                        formatted_dataset_list = self.get_non_empty_answer(formatted_dataset_list)
                        random.shuffle(formatted_dataset_list)
                    
                    return formatted_dataset_list, True
            except Exception as e:
                print(f"âš ï¸ è¯»å–ç¼“å­˜å¤±è´¥: {e}ï¼Œå°†å›é€€åˆ°ä¸‹è½½æ¨¡å¼ã€‚")

        # 2. å¦‚æœæ— ç¼“å­˜æˆ–å¼ºåˆ¶é‡è½½ï¼Œä¸‹è½½åŸå§‹æ•°æ®
        origin_dataset = self.download_dataset()
        # æ³¨æ„ï¼šè¿™é‡Œæˆ‘ä»¬ä¸å¯¹åŸå§‹æ•°æ®åš filter_empty_answerï¼Œ
        # å› ä¸ºåŸå§‹æ•°æ®æ ¼å¼å„å¼‚ï¼Œ'answers' å­—æ®µå¯èƒ½è¿˜æœªç”Ÿæˆï¼Œè¿‡æ»¤é€šå¸¸æ”¾åœ¨ format ä¹‹åæˆ–æœŸé—´ã€‚
        return origin_dataset, False
    
    def format_dataset(self, origin_dataset: List[Dict[str, Any]]) -> Dict[str, Any]:
        """
        æ ¼å¼åŒ–æ•°æ®é›†ï¼ˆä»…é’ˆå¯¹åŸå§‹æ•°æ®è°ƒç”¨ï¼‰ã€‚
        åŒ…å«ï¼šæ ¼å¼è½¬æ¢ -> BM25æ£€ç´¢å¹²æ‰°é¡¹ -> ä¿å­˜ç¼“å­˜ã€‚
        """
        formatted_dataset_dict = {}
        formatted_dataset_list = []

        iterator = tqdm(origin_dataset, desc="Formatting dataset", unit="sample")

        for sample in iterator:
            if self.format:
                # è°ƒç”¨å­ç±»å®ç°çš„ format_item å’ŒåŸºç±»çš„ construct_context_and_facts
                formatted_sample = self.format_sample(sample)
            else:
                formatted_sample = sample
            
            formatted_dataset_list.append(formatted_sample)
            formatted_dataset_dict[formatted_sample["id"]] = formatted_sample

        # è¿‡æ»¤ä¸æ‰“ä¹±
        if self.filter_empty_answer:
            formatted_dataset_list = self.get_non_empty_answer(formatted_dataset_list)
            # æ›´æ–° dict ä»¥åŒ¹é… filter åçš„ list
            formatted_dataset_dict = {sample["id"]: sample for sample in formatted_dataset_list}
            random.shuffle(formatted_dataset_list)
        
        # æ›´æ–°ç±»æˆå‘˜
        self.dataset_list = formatted_dataset_list

        # ä¿å­˜ç¼“å­˜
        if self.offline and self.cache_path:
            os.makedirs(os.path.dirname(self.cache_path), exist_ok=True)
            with open(self.cache_path, "w", encoding='utf-8') as f:
                print(f"Saving formatted dataset to cache: {self.cache_path}")
                # ä¿å­˜çš„æ˜¯ List
                json.dump(
                    formatted_dataset_list,
                    f,
                    ensure_ascii=False,
                    indent=4,
                )

        return formatted_dataset_dict
    
    def get_non_empty_answer(self, data: list) -> list:
        """è¿‡æ»¤æ‰ç­”æ¡ˆä¸ºç©ºçš„æ ·æœ¬"""
        return [
            sample for sample in data 
            if "answers" in sample 
            and isinstance(sample["answers"], list) 
            and len(sample["answers"]) > 0 
            and str(sample["answers"][0]).strip() != ""
        ]

    def format_sample(self, sample: Dict[str, Any]) -> Dict[str, Any]:
        """
        æ ¼å¼åŒ–å•ä¸ªæ•°æ®æ ·æœ¬ï¼šåŸå§‹æ•°æ® -> ä¸­é—´æ ¼å¼ -> æ·»åŠ BM25ä¸Šä¸‹æ–‡ -> æœ€ç»ˆæ ¼å¼
        """
        # 1. è°ƒç”¨å­ç±»è½¬æ¢é€»è¾‘ (Raw -> Standard Schema)
        item = self.format_item(sample)
        
        # 2. æ„å»ºä¸Šä¸‹æ–‡ (Retrieval & Distractors)
        context, facts = self.construct_context_and_facts(item)

        # 3. ç»„è£…æœ€ç»ˆæ ·æœ¬
        formatted_sample = {
            "id": item['id'],
            "query": item['query'],
            "answers": item['answers'],
            "context": "\n\n".join(context),
            "facts": facts,
            "corpus": item['corpus'],
            "extra": item.get('extra', None),
            "dataset": self.dataset_path if 'dataset' not in sample else sample['dataset'],
        }

        return formatted_sample

    # ------------------------------------------------------------------------
    # Abstract Methods
    # ------------------------------------------------------------------------
    @abstractmethod
    def format_item(self, sample: Dict[str, Any]) -> Dict[str, Any]:
        """
        [å­ç±»å¿…é¡»å®ç°]
        å°†åŸå§‹æ•°æ®æ ·æœ¬è½¬æ¢ä¸ºåŒ…å« id, query, answers, corpus çš„æ ‡å‡†ä¸­é—´æ ¼å¼ã€‚
        """
        raise NotImplementedError("å­ç±»å¿…é¡»å®ç° format_item æ–¹æ³•")

    # ------------------------------------------------------------------------
    # Corpus & Context Construction
    # ------------------------------------------------------------------------
    @staticmethod
    def string_context(title: str, sentences: List[str]) -> str:
        return "###" + str(title).upper() + "\n" + " ".join(sentences)
    
    @staticmethod
    def string_sub_id(id: str, idx: int) -> str:
        return f"{id}___{idx}"

    def construct_corpus(self, data: List[Dict[str, Any]], is_formatted: bool = False) -> List[Dict[str, Any]]:
        """
        æ„å»ºç”¨äº BM25 æ£€ç´¢çš„è¯­æ–™åº“ã€‚
        
        Args:
            data: æ•°æ®åˆ—è¡¨
            is_formatted: å¦‚æœä¸º Trueï¼Œè¡¨ç¤º data å·²ç»æ˜¯æ ¼å¼åŒ–åçš„ï¼ˆåŒ…å« corpus å­—æ®µï¼‰ï¼Œ
                          æ— éœ€å†æ¬¡è°ƒç”¨ format_itemã€‚
        """
        global_corpus = []
        
        # ä½¿ç”¨ set è¿›è¡Œå»é‡ï¼Œkey ä¸º text å†…å®¹
        seen_texts = set()

        for sample in tqdm(data, desc="Constructing corpus"):
            # ç­–ç•¥æ¨¡å¼ï¼šæ ¹æ®æ•°æ®æ¥æºå†³å®šå¦‚ä½•è§£æ
            if is_formatted:
                # æ¥è‡ªç¼“å­˜ï¼Œç›´æ¥ä½¿ç”¨ç»“æ„åŒ–æ•°æ®
                if 'corpus' in sample:
                    _id = sample['id']
                    corpus_items = sample['corpus']
                else:
                    # å¼‚å¸¸æƒ…å†µï¼šç¼“å­˜æ•°æ®ç»“æ„ä¸å®Œæ•´ï¼Œè·³è¿‡
                    continue
            else:
                # æ¥è‡ªåŸå§‹æºï¼Œéœ€è¦è½¬æ¢
                formated_item = self.format_item(sample) 
                _id = formated_item["id"]
                corpus_items = formated_item['corpus']
            
            # å±•å¹³ corpus
            for idx, context in enumerate(corpus_items):
                text = self.string_context(context['title'], context['sentences'])
                
                # å†…å­˜ä¼˜åŒ–ï¼šç›´æ¥åœ¨å¾ªç¯ä¸­å»é‡ï¼Œé¿å…æ„å»ºè¿‡å¤§çš„åˆ—è¡¨åå†å»é‡
                if text not in seen_texts:
                    seen_texts.add(text)
                    global_corpus.append({
                        "id": self.string_sub_id(_id, idx),
                        "text": text,
                    })
        
        return global_corpus

    def construct_context_and_facts(self, format_item: Dict[str, Any]) -> Tuple[List[str], List[str]]:
        """
        åŸºäº Gold Context å’Œ BM25 æ£€ç´¢æ„å»ºæœ€ç»ˆçš„ context å’Œ factsã€‚
        """
        _id = format_item["id"]
        query = format_item['query']
        single_corpus = format_item['corpus']

        gold_context = []
        gold_ctx_ids = set() # ä½¿ç”¨ set åŠ é€ŸæŸ¥æ‰¾
        facts = []
        
        # 1. æå– Gold Context
        for idx, item in enumerate(single_corpus):
            if item.get('facts'): # å¦‚æœæœ‰ factsï¼Œè§†ä½œ gold
                ctx_str = self.string_context(item['title'], item['sentences'])
                gold_context.append(ctx_str)
                gold_ctx_ids.add(self.string_sub_id(_id, idx))
                facts.extend(item['facts'])
        
        distractor_context = []
        
        # 2. BM25 æ£€ç´¢å¹²æ‰°é¡¹
        if self.distractor_docs > 0:
            # æ£€ç´¢æ•°é‡ = éœ€è¦çš„å¹²æ‰°é¡¹ + å·²æœ‰çš„Goldé¡¹ + ç¼“å†²(10)
            k_val = self.distractor_docs + len(gold_context) + 10
            candidate_distractor_context = self.bm25.retrieve(query, k=k_val)

            distractor_count = 0
            for item in candidate_distractor_context:
                # æ’é™¤å·²ç»æ˜¯ gold çš„æ–‡æ¡£
                if item['id'] not in gold_ctx_ids and item['text'] not in gold_context:
                    distractor_context.append(item['text'])
                    distractor_count += 1
                    if distractor_count >= self.distractor_docs:
                        break
        
        # 3. åˆå¹¶ä¸æ··æ´—
        if self.unanswerable:
            context = distractor_context
            facts = [] # ä¸å¯å›ç­”æ¨¡å¼ä¸‹æ¸…é™¤ facts
        else:
            context = gold_context + distractor_context

        # ä½¿ç”¨å±€éƒ¨éšæœºç§å­æˆ–å…¨å±€ç§å­ï¼Œè¿™é‡Œä¿æŒåŸæœ‰é€»è¾‘
        # å»ºè®®ï¼šå¦‚æœå¸Œæœ›å¤šæ¬¡è¿è¡Œä¸å›ºå®šï¼Œå¯ä»¥å»æ‰ seed(42)ï¼Œæˆ–è€…åœ¨ init é‡Œä¼ å…¥ seed
        rng = random.Random(42) 
        rng.shuffle(context)

        return context, facts

    # ------------------------------------------------------------------------
    # Utility Methods
    # ------------------------------------------------------------------------
    def get_length(self) -> int:
        return len(self.dataset)

    def get_sample(self, sample_id=None) -> Dict[str, Any]:
        if not self.dataset:
            return None
        
        if sample_id:
            return self.dataset.get(sample_id)
        else:
            sample_id = random.choice(list(self.dataset.keys()))
            return self.dataset[sample_id]

    def random_sample(self) -> Dict[str, Any]:
        if not self.dataset:
            print("Dataset is empty.")
            return {}

        sample_id = random.choice(list(self.dataset.keys()))
        sample = self.dataset[sample_id]
        
        print(f"ID: {sample_id}")
        print("-" * 20)
        print(f"Query: {sample['query']}")
        print("-" * 20)
        # æˆªæ–­è¿‡é•¿çš„ context æ˜¾ç¤ºï¼Œé¿å…åˆ·å±
        print(f"Context (Preview): {sample['context'][:500]}..." if len(sample['context']) > 500 else f"Context: {sample['context']}")
        print("-" * 20)
        print(f"Answers: {sample['answers']}")
        print("-" * 20)
        if "facts" in sample:
            print(f"Supporting Facts: {sample['facts']}")
        
        return sample