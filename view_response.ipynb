{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "29803ac6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from copypastelrm.utils.json_tools import read_json\n",
    "import numpy as np\n",
    "\n",
    "from copypastelrm.metrics.utils import extract_answer_and_facts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9fd538fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"/home/lyc/projects/CopyPasteLRM/results/infer/test/Qwen3-4B-Instruct-2507/resamples_-1/seed_42/tpr_0.0/copypaste-prompt_rag-1766424839.json\"\n",
    "results = read_json(path)\n",
    "info = results['info']\n",
    "data = results['data']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4d1ef6b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "找到了\n",
      "data/multirc/dev.json\n",
      "predict answer len:  8.0\n",
      "golden answer len:  4.0\n",
      "Atipico1/popQA\n",
      "predict answer len:  2.0\n",
      "golden answer len:  2.0\n",
      "data/2WikiMultihopQA/dev.json\n",
      "predict answer len:  3.0\n",
      "golden answer len:  2.0\n",
      "hotpotqa/hotpot_qa\n",
      "predict answer len:  2.0\n",
      "golden answer len:  2.0\n",
      "Salesforce/FaithEval-counterfactual-v1.0\n",
      "predict answer len:  15.0\n",
      "golden answer len:  4.0\n",
      "qiaojin/PubMedQA\n",
      "predict answer len:  34.0\n",
      "golden answer len:  1.0\n",
      "allenai/qasper\n",
      "predict answer len:  36.0\n",
      "golden answer len:  6.6\n",
      "dgslibisey/MuSiQue\n",
      "predict answer len:  4.0\n",
      "golden answer len:  2.0\n"
     ]
    }
   ],
   "source": [
    "distribution = {}\n",
    "\n",
    "id = \"MCAS_2013_5_29411\"\n",
    "\n",
    "for sample_id, item in data.items():\n",
    "    if sample_id == id:\n",
    "        print('找到了')\n",
    "    dataset = item['dataset']\n",
    "    predict = item['predict']\n",
    "    answers = item['answer']\n",
    "    predict_answer, predict_facts = extract_answer_and_facts(predict)\n",
    "    if dataset not in distribution:\n",
    "        distribution[dataset] = {\n",
    "            \"predict_answer_len\": [],\n",
    "            \"golden_answer_len\": []\n",
    "        }\n",
    "    distribution[dataset][\"predict_answer_len\"].append(len(predict_answer.split()) if predict_answer else 0)\n",
    "    distribution[dataset][\"golden_answer_len\"].append(np.mean([len(ans.split()) for ans in answers]))\n",
    "\n",
    "for dataset, item in distribution.items():\n",
    "    print(dataset)\n",
    "    print(\"predict answer len: \", np.median(item[\"predict_answer_len\"]))\n",
    "    print(\"golden answer len: \", np.median(item[\"golden_answer_len\"]))\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ms-swift",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
